I was able to complete the required assignments, completing the todo checklist. I had only one issue while configuring AWS CLI environment variables, that I configured wrong one of them. After fixing it, I was able to start Gitpod from a fresh workspace having AWS CLI installed and configured with my account and credentials.
For architecture diagrams, I've created both a conceptual and a logical diagrams in Lucid Charts.
For billing alarms and budget I've used AWS CLI commands with the corresponding json files instead of creating them using AWS Console GUI, because I prefer to have a repeatable way of doing it, and I can have those commands documented in text format instead of having a set of instructions to do that in AWS GUI.

----------------------------------------------------------------------------------------------------------------------------------

In week 1, I was able to complete the required assignments.

- First of all, I've run backend app directly, no containers, to verify it is working
- Created Dockerfile for backend, running again with no issues (same behavior as before), checked container in VSCode extension
- Created Dockerfile for frontend, and run with no issues, opening Cruddur page
- Created Compose file for orchestrating backend and frontend apps, the only issue found is the need to run npm install before starting compose (configured Gitpod workspace to run it on start)
- Added the new notifications endpoint to OpenAPI doc
- Added the required code to backend for implementing notifications endpoint
- Added react page to frontend for implementing notifications
- Ran DynamoDB container and checked by using AWS CLI commands
- Ran Postgres container and checked by using psql client (also installed in Gitpod environment on start)

For homework challenges,
- Used docker locally in my Windows machine with WSL
- Tagged and pushed backend-flask to a new own repository in Docker Hub
- Modified backend Dockerfile for using multi-stage images and implemented some best practices, verifying later that container worked as before

Finally, I've submitted both Knowledge Challenges (security and pricing)

----------------------------------------------------------------------------------------------------------------------------------

In week 2, I was able to complete the required assignments.

- First of all, I watched week-2 live stream on Saturday, then I completed watching the other videos (Chirag's pricing recommendations, Ashish's security in observability, and the rest of the complementary videos, including the one Andrew recorded for solving x-day subsegments)
- I could implement honeycomb instrumentation in backend-flask application, adding spans and attributes.
- For AWS X-ray, I've implemented instrumentation, had no issues running the x-ray daemon container, I could create an AWS log group and sampling rule, and finally, after some troubleshooting, I could implement x-ray subsegments, before watching Andrew's video and Olga's video. It was a little tricky, but It was a good programming exercise.
- For CloudWatch, I could be able to implement it by importing watchtower python module and generating some logs that I could see in the AWS CloudWatch console (the typical Hello Cloudwatch! as an example)
- Finally, for Rollbar, I was able to implement also in the backend-flask app, and tested it by forcing an error in one of the endpoints. I could be able to see the error in Rollbar.

For homework challenges, I wasn't able to complete any of them.

Finally, I've submitted the Knowledge Challenges (security and pricing)

As a bonus, following Andrew's video about Codespaces, I've configured my environment for using it to develop and test cruddur, configuring devcontainer file, compose environment and testing frontend and backend integration successfully.

----------------------------------------------------------------------------------------------------------------------------------

In week 3, I was able to complete the required assignments.

- First of all, I watched week-3 live stream on Saturday, then I continued watching the rest of the videos, that showed how to implement completely Cognito authentication both in frontend and backend. I also watched Ashish video about centralized authentication.
- For software asignments, I could be able to create the required Amazon Cognito user pool, using ClickOps as specified (although my idea is to investigate later how to create it using AWS CLI).
- In frontend application, I implemented Amplify library and changed login, signup, recovery and forgot password pages in order to use cognito authentication instead of cookies. Also I made the changes to show or hide corresponding elements based on user login status.
- Finally, I implemented JWT token validation in backend for protecting api endpoints (I watched Andrew's video about several ways to validate token, client side, using decryption keys to validate authenticity of the token, vs server side, in which the token is validated invoking AWS api that expect a valid token)
- As an extra, having watched Andrew video about how to improve UI contrast, I've implemented those changes in my repository.

----------------------------------------------------------------------------------------------------------------------------------

In week 4, I was able to complete all the required assignments.

- First, I've created the RDS instance in AWS using the script, creating the corresponding environment variables in Gitpod for not exposing credentials in git repo.
- I've explored the different options for creating a AWS RDS instance using AWS console, instead of CLI.
- After RDS instance is created, I've checked different configurations and options in AWS console, and stopped it for not consuming credits (I'll be using it later).
- For implementing postgres in cruddur, first of all I'm doing locally, so I've enabled postgres container and ran it along the backend and frontend.
- I've ensured that postgres client is installed during Gitpod workspace initialization.
- I've configured environment variables for connecting to postgres, both locally and RDS instance.
- I've created several scripts (and made them executable) for implementing some operations against db (connect, create db, drop db, schema load, seed data, check sessions, db setup). 
- All these scripts are configured with the possibility to be ran against local db or RDS instance.
- In backend application, I've imported psycopg modules, and made the changes in the code for retrieving activities from db (removing hardcoded ones).
- For connecting Gitpod to AWS RDS, a security group rule was created, and in Gitpod initialization the current ip address is retrieved and configured automatically in AWS RDS.
- I've connected to RDS and executed schema load and seed data for having sql structure ready in RDS.
- I've tested cruddur using AWS RDS successfully.
- I've created an AWS lambda for inserting new users in RDS after successful signup. Required environment variable for connection was configured in the lambda.
- The lambda was also configured with the required layer using python 3.8 and a trigger was added to be executed on post confirmation signup.
- Created lambda is required to be assigned to the same VPC used by RDS, so I've tried configuring it,
- I've faced a permissions error while saving, so I've added the required permissions to create network card on lambda execution, by using IAM roles and policies.
- I've tested signup process successfully, verifying that the created user in Cognito appears also in RDS users table (I've also checked CloudWatch logs).
- Finally, for completing RDS integration, I've added the required code to save activities to db, by implementing a refactor in db library with the corresponding sql files.
- I had to implement a changed I've found in Discord, for passing the correct user_handle from frontend to backend and then to db, because I had a null error because the passed user handle was always andrebrown.
- I've implemented a change in lambda code in order to use sql parameters instead of passing values directly in sql code (more secure)
- Finally, I was able to test the complete flow, creating a new user and inserting activities from that user, verifying information in the page and also in db by querying RDS.
- At the moment of writing, there were no homework challenges to do, anyway, I consider this was a hard week to complete the required homework.
- About knowledge challenge, I've completed security quiz successfully (Having watched Ashish's video was very useful for that)

----------------------------------------------------------------------------------------------------------------------------------

In week 5, I was able to complete all the required assignments.

- 

docker compose  -f "docker-compose.yml" up -d --build db dynamodb-local
docker compose  -f "docker-compose.yml" up -d

cd backend-flask
./bin/db/setup
./bin/db/drop

./bin/ddb/schema-load
./bin/ddb/list-tables
./bin/ddb/drop cruddur-messages

./bin/ddb/seed

./bin/ddb/scan

./bin/ddb/patterns/get-conversation
./bin/ddb/patterns/list-conversations

./bin/cognito/list-users
./bin/db/update_cognito_user_ids

----------------------------------------------------------------------------------------------------------------------------------
